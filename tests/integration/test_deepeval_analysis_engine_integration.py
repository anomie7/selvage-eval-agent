"""
DeepEvalAnalysisEngine í†µí•© í…ŒìŠ¤íŠ¸
"""
import pytest
import os
from pathlib import Path

from selvage_eval.analysis.deepeval_analysis_engine import DeepEvalAnalysisEngine


class TestDeepEvalAnalysisEngineIntegration:
    """DeepEvalAnalysisEngine í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def test_analyze_session_with_default_paths(self):
        """DeepEval ë¶„ì„ ì—”ì§„ ê¸°ë³¸ ê²½ë¡œ í…ŒìŠ¤íŠ¸"""
        # DeepEval í…”ë ˆë©”íŠ¸ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±
        deepeval_dir = Path(".deepeval")
        deepeval_dir.mkdir(exist_ok=True)
        telemetry_file = deepeval_dir / ".deepeval_telemetry.txt"
        if not telemetry_file.exists():
            telemetry_file.touch()
        
        try:
            # DeepEvalAnalysisEngine ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            analysis_engine = DeepEvalAnalysisEngine()
            
            # ì§€ì •ëœ session_idë¡œ analyze_session í˜¸ì¶œ (ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
            session_id = 'eval_20250708_012833_39bb3ebc'
            
            # ê¸°ë³¸ ê²½ë¡œ í™•ì¸
            expected_deepeval_path = Path("/Users/demin_coder/Library/selvage-eval/deepeval_results") / session_id
            assert expected_deepeval_path.exists(), f"DeepEval ê²°ê³¼ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {expected_deepeval_path}"
            
            # ë¶„ì„ ì‹¤í–‰ (deepeval_results_pathì™€ output_dir ëª¨ë‘ ê¸°ë³¸ê°’ ì‚¬ìš©)
            result = analysis_engine.analyze_session(session_id)
            
            # ê²°ê³¼ ê²€ì¦
            assert result is not None, "ë¶„ì„ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤"
            assert "analysis_metadata" in result, "ë¶„ì„ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            assert "files_generated" in result, "ìƒì„±ëœ íŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ë©”íƒ€ë°ì´í„° ê²€ì¦
            metadata = result["analysis_metadata"]
            assert "analysis_timestamp" in metadata, "ë¶„ì„ ì‹œê°„ì´ ì—†ìŠµë‹ˆë‹¤"
            assert "session_path" in metadata, "ì„¸ì…˜ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤"
            assert "total_test_cases" in metadata, "ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤"
            assert "models_analyzed" in metadata, "ë¶„ì„ëœ ëª¨ë¸ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤"
            
            # ìƒì„±ëœ íŒŒì¼ ê²€ì¦
            files_generated = result["files_generated"]
            assert "markdown_report" in files_generated, "ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤"
            assert "json_data" in files_generated, "JSON ë°ì´í„° ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤"
            assert "visualization_files" in files_generated, "ì‹œê°í™” íŒŒì¼ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤"
            
            # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ í™•ì¸
            markdown_path = Path(files_generated["markdown_report"])
            json_path = Path(files_generated["json_data"])
            
            assert markdown_path.exists(), f"ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {markdown_path}"
            assert json_path.exists(), f"JSON ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {json_path}"
            
            # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
            expected_output_dir = Path("~/Library/selvage-eval/analyze_results").expanduser() / session_id
            assert markdown_path.parent == expected_output_dir, f"ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {markdown_path.parent} vs {expected_output_dir}"
            
            # íŒŒì¼ ë‚´ìš© ê¸°ë³¸ ê²€ì¦
            assert markdown_path.stat().st_size > 0, "ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            assert json_path.stat().st_size > 0, "JSON ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            
            # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ê¸°ë³¸ êµ¬ì¡° í™•ì¸
            with open(markdown_path, 'r', encoding='utf-8') as f:
                markdown_content = f.read()
                assert "DeepEval ë¶„ì„ ë³´ê³ ì„œ" in markdown_content, "ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤"
                assert "ë°ì´í„° ìš”ì•½" in markdown_content, "ë°ì´í„° ìš”ì•½ ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤"
                assert "ë¶„ì„ ì‹œê°„" in markdown_content, "ë¶„ì„ ì‹œê°„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ì‹œê°í™” ë””ë ‰í† ë¦¬ í™•ì¸ (ìƒì„± ì‹œë„ë˜ì—ˆëŠ”ì§€)
            visualization_dir = expected_output_dir / "visualizations"
            if visualization_dir.exists():
                assert visualization_dir.is_dir(), "ì‹œê°í™” ë””ë ‰í† ë¦¬ê°€ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤"
            
            print(f"âœ… ë¶„ì„ ì„±ê³µ!")
            print(f"ğŸ“Š ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {metadata['total_test_cases']}")
            print(f"ğŸ¤– ë¶„ì„ëœ ëª¨ë¸: {metadata['models_analyzed']}")
            print(f"ğŸ“ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ: {markdown_path}")
            print(f"ğŸ“„ JSON ë°ì´í„°: {json_path}")
            print(f"ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {expected_output_dir}")
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if telemetry_file.exists():
                telemetry_file.unlink()
            if deepeval_dir.exists() and not any(deepeval_dir.iterdir()):
                deepeval_dir.rmdir()