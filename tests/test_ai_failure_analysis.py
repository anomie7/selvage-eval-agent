"""AI ê¸°ë°˜ ì‹¤íŒ¨ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""

import pytest
from unittest.mock import Mock, patch, MagicMock
from selvage_eval.analysis.deepeval_analysis_engine import DeepEvalAnalysisEngine


@pytest.fixture
def mock_engine():
    """í…ŒìŠ¤íŠ¸ìš© ë¶„ì„ ì—”ì§„ ìƒì„±"""
    with patch('selvage_eval.analysis.deepeval_analysis_engine.os.getenv') as mock_getenv:
        mock_getenv.return_value = "test_api_key"
        
        with patch('selvage_eval.llm.gemini_client.GeminiClient') as mock_client_class:
            # Flash í´ë¼ì´ì–¸íŠ¸ ëª¨í‚¹
            mock_flash_client = Mock()
            # Pro í´ë¼ì´ì–¸íŠ¸ ëª¨í‚¹  
            mock_pro_client = Mock()
            
            # í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹œ ëª¨ë¸ëª…ì— ë”°ë¼ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
            def create_client(*args, **kwargs):
                if 'gemini-2.5-pro' in str(kwargs.get('model_name', '')):
                    return mock_pro_client
                return mock_flash_client
            
            mock_client_class.side_effect = create_client
            
            engine = DeepEvalAnalysisEngine()
            engine.gemini_client = mock_flash_client
            engine.gemini_pro_client = mock_pro_client
            
            return engine, mock_flash_client, mock_pro_client


def test_ai_failure_analysis_basic(mock_engine):
    """AI ì‹¤íŒ¨ ë¶„ì„ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    engine, mock_flash_client, mock_pro_client = mock_engine
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    failed_metrics = {
        'correctness': {
            'failure_count': 3,
            'translated_reasons': [
                'ì½”ë“œì˜ ë…¼ë¦¬ì  ì˜¤ë¥˜ê°€ ë°œê²¬ë¨',
                'ì˜ˆìƒ ì¶œë ¥ê³¼ ì‹¤ì œ ì¶œë ¥ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ',
                'í•¨ìˆ˜ ë™ì‘ì´ ëª…ì„¸ì™€ ë‹¤ë¦„'
            ]
        },
        'clarity': {
            'failure_count': 2,
            'translated_reasons': [
                'ì½”ë“œ ì£¼ì„ì´ ë¶ˆì¶©ë¶„í•¨',
                'ë³€ìˆ˜ëª…ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ'
            ]
        }
    }
    
    # Gemini Pro ì‘ë‹µ ëª¨í‚¹
    mock_analysis_response = """
### 1. í•µì‹¬ ì‹¤íŒ¨ íŒ¨í„´ ìš”ì•½
- ë…¼ë¦¬ì  ì˜¤ë¥˜: ì½”ë“œì˜ ê¸°ë³¸ ë™ì‘ ë¡œì§ì— ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°
- ëª…ì„¸ ë¶ˆì¼ì¹˜: ì„¤ê³„ ëª…ì„¸ì™€ êµ¬í˜„ ì‚¬ì´ì˜ ë¶ˆì¼ì¹˜ 
- ê°€ë…ì„± ë¶€ì¡±: ì½”ë“œ ì´í•´ë¥¼ ìœ„í•œ ì •ë³´ ë¶€ì¡±

### 2. ë©”íŠ¸ë¦­ë³„ ë¶„ë¥˜ ë° íŠ¹ì„± ë¶„ì„
ì •í™•ì„± ë©”íŠ¸ë¦­ì—ì„œ í•µì‹¬ ê¸°ëŠ¥ ì˜¤ë¥˜ê°€ ì§‘ì¤‘ë˜ì–´ ìˆìœ¼ë©°, ëª…í™•ì„± ë©”íŠ¸ë¦­ì—ì„œëŠ” ë¬¸ì„œí™” ë° ë„¤ì´ë° ì´ìŠˆê°€ ì£¼ë¥¼ ì´ë£¸.

### 3. ê·¼ë³¸ ì›ì¸ ë¶„ì„
ì‹œìŠ¤í…œì  ë¬¸ì œë¡œ íŒë‹¨ë˜ë©°, ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê°•í™”ê°€ í•„ìš”í•¨.

### 4. êµ¬ì²´ì  ê°œì„  ë°©ì•ˆ
- ë‹¨ê¸°: ìë™í™”ëœ ì •ì  ë¶„ì„ ë„êµ¬ ë„ì…
- ì¤‘ê¸°: ì½”ë“œ ë¦¬ë·° ê°€ì´ë“œë¼ì¸ ìˆ˜ë¦½
- ì¥ê¸°: ê°œë°œì êµìœ¡ í”„ë¡œê·¸ë¨ ìš´ì˜

### 5. ë¦¬ìŠ¤í¬ ë° ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
ë…¼ë¦¬ì  ì˜¤ë¥˜ ë°œìƒë¥  ì§€ì† ëª¨ë‹ˆí„°ë§ í•„ìš”
"""
    
    mock_pro_client.query.return_value = mock_analysis_response
    
    # AI ë¶„ì„ ì‹¤í–‰
    result = engine._analyze_metric_failures_with_ai(failed_metrics)
    
    # ê²°ê³¼ ê²€ì¦
    assert result is not None
    assert 'analysis_content' in result
    assert 'analyzed_metrics' in result
    assert 'total_failures_analyzed' in result
    assert 'analysis_timestamp' in result
    
    assert result['total_failures_analyzed'] == 5  # 3 + 2
    assert 'correctness' in result['analyzed_metrics']
    assert 'clarity' in result['analyzed_metrics']
    assert 'í•µì‹¬ ì‹¤íŒ¨ íŒ¨í„´ ìš”ì•½' in result['analysis_content']
    
    # Gemini Pro í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ ê²€ì¦
    mock_pro_client.query.assert_called_once()
    call_args = mock_pro_client.query.call_args
    assert 'messages' in call_args[1]
    assert 'system_instruction' in call_args[1]
    
    # ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ê²€ì¦
    system_instruction = call_args[1]['system_instruction']
    assert '10ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´' in system_instruction
    assert 'ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€' in system_instruction
    assert 'í…Œí¬ë‹ˆì»¬ ë¼ì´í„°' in system_instruction


def test_ai_failure_analysis_empty_metrics(mock_engine):
    """ë¹ˆ ë©”íŠ¸ë¦­ ë°ì´í„°ì— ëŒ€í•œ AI ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    engine, _, _ = mock_engine
    
    # ë¹ˆ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    result = engine._analyze_metric_failures_with_ai({})
    assert result is None


def test_ai_failure_analysis_no_gemini_pro_client(mock_engine):
    """Gemini Pro í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš° í…ŒìŠ¤íŠ¸"""
    engine, _, _ = mock_engine
    engine.gemini_pro_client = None
    
    failed_metrics = {
        'correctness': {
            'failure_count': 1,
            'translated_reasons': ['í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨']
        }
    }
    
    result = engine._analyze_metric_failures_with_ai(failed_metrics)
    assert result is None


def test_ai_failure_analysis_gemini_error(mock_engine):
    """Gemini API ì˜¤ë¥˜ ë°œìƒ ì‹œ í…ŒìŠ¤íŠ¸"""
    engine, _, mock_pro_client = mock_engine
    
    # API ì˜¤ë¥˜ ëª¨í‚¹
    mock_pro_client.query.side_effect = Exception("API Error")
    
    failed_metrics = {
        'correctness': {
            'failure_count': 1,
            'translated_reasons': ['í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨']
        }
    }
    
    result = engine._analyze_metric_failures_with_ai(failed_metrics)
    assert result is None


def test_markdown_report_includes_ai_analysis(mock_engine):
    """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œì— AI ë¶„ì„ì´ í¬í•¨ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
    engine, _, mock_pro_client = mock_engine
    
    # AI ë¶„ì„ ì‘ë‹µ ëª¨í‚¹
    mock_analysis_response = "AI ë¶„ì„ ê²°ê³¼ ë‚´ìš©"
    mock_pro_client.query.return_value = mock_analysis_response
    
    # í…ŒìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ ë°ì´í„° - ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
    analysis_results = {
        'model_failure_analysis': {
            'model1': {
                'total_tests': 5,
                'total_failures': 2,  # total_failures > 0ì´ì–´ì•¼ ìƒì„¸ ë¶„ì„ì´ ì‹¤í–‰ë¨
                'failure_rate': 0.4,
                'failed_metrics': {
                    'correctness': {
                        'failure_count': 2,
                        'avg_confidence': 0.75,
                        'translated_reasons': ['ì˜¤ë¥˜1', 'ì˜¤ë¥˜2']
                    }
                }
            }
        }
    }
    
    # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
    report = engine._generate_markdown_report(analysis_results)
    
    # AI ë¶„ì„ ì„¹ì…˜ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
    assert 'ğŸ¤– AI ê¸°ë°˜ ì‹¤íŒ¨ ì‚¬ìœ  ë¶„ì„' in report
    assert 'AI ë¶„ì„ ê²°ê³¼ ë‚´ìš©' in report
    assert 'ë¶„ì„ ëŒ€ìƒ' in report
    assert 'ì´ ë¶„ì„ ì‹¤íŒ¨ ê±´ìˆ˜' in report


def test_prompt_engineering_quality(mock_engine):
    """í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í’ˆì§ˆ ê²€ì¦"""
    engine, _, mock_pro_client = mock_engine
    
    failed_metrics = {
        'correctness': {
            'failure_count': 1,
            'translated_reasons': ['í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜']
        }
    }
    
    mock_pro_client.query.return_value = "ë¶„ì„ ê²°ê³¼"
    
    # AI ë¶„ì„ ì‹¤í–‰
    engine._analyze_metric_failures_with_ai(failed_metrics)
    
    # í”„ë¡¬í”„íŠ¸ ë‚´ìš© ê²€ì¦
    call_args = mock_pro_client.query.call_args
    user_message = call_args[1]['messages'][0]['content']
    system_instruction = call_args[1]['system_instruction']
    
    # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìš”ì†Œë“¤ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
    assert 'í•µì‹¬ ì‹¤íŒ¨ íŒ¨í„´ ìš”ì•½' in user_message
    assert 'ë©”íŠ¸ë¦­ë³„ ë¶„ë¥˜ ë° íŠ¹ì„± ë¶„ì„' in user_message  
    assert 'ê·¼ë³¸ ì›ì¸ ë¶„ì„ ë° ì‹¤í–‰ ê³„íš' in user_message
    assert 'ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ê¶Œê³ ì‚¬í•­' in user_message
    assert '1ì£¼ì¼ ë‚´ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê¸° ê°œì„ ì±…' in user_message
    assert '1ê°œì›” ë‚´ ì™„ë£Œ ê°€ëŠ¥í•œ ì¤‘ê¸° ê°œì„ ì±…' in user_message
    assert 'ì‹¤ì œ ë°ì´í„°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©' in user_message
    
    # í˜ë¥´ì†Œë‚˜ ê²€ì¦
    assert '10ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´' in system_instruction
    assert 'ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€' in system_instruction
    assert 'í…Œí¬ë‹ˆì»¬ ë¼ì´í„°' in system_instruction


def test_ai_failure_summary_generation(mock_engine):
    """AI ì‹¤íŒ¨ ë¶„ì„ ì¢…í•© ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸"""
    engine, _, mock_pro_client = mock_engine
    
    # ëª¨ë¸ë³„ ì‹¤íŒ¨ ë¶„ì„ ë°ì´í„° ì¤€ë¹„
    model_failure_analysis = {
        'model1': {
            'total_failures': 5,
            'failed_metrics': {
                'correctness': {
                    'failure_count': 3,
                    'translated_reasons': ['ë¡œì§ ì˜¤ë¥˜ ë°œìƒ', 'ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ']
                },
                'clarity': {
                    'failure_count': 2,
                    'translated_reasons': ['ì£¼ì„ ë¶€ì¡±', 'ê°€ë…ì„± ë¬¸ì œ']
                }
            }
        },
        'model2': {
            'total_failures': 3,
            'failed_metrics': {
                'actionability': {
                    'failure_count': 2,
                    'translated_reasons': ['ì‹¤í–‰ ë°©ì•ˆ ë¶€ì¡±']
                },
                'json_correctness': {
                    'failure_count': 1,
                    'translated_reasons': ['JSON í˜•ì‹ ì˜¤ë¥˜']
                }
            }
        }
    }
    
    # AI ë¶„ì„ ì‘ë‹µ ëª¨í‚¹
    mock_analysis_response = """
    ### 1. í•µì‹¬ ì‹¤íŒ¨ íŒ¨í„´ ìš”ì•½
    - ë¡œì§ ì˜¤ë¥˜ (40%): ì•Œê³ ë¦¬ì¦˜ ê²€ì¦ ë¶€ì¡±
    - ë¬¸ì„œí™” ë¶€ì¡± (30%): ì£¼ì„ ë° ì„¤ëª… ë¯¸í¡
    - ì‹¤í–‰ ê°€ëŠ¥ì„± (30%): êµ¬ì²´ì  ë°©ì•ˆ ì œì‹œ ë¶€ì¡±
    
    ### 2. ë©”íŠ¸ë¦­ë³„ ë¶„ë¥˜ ë° íŠ¹ì„± ë¶„ì„
    ì •í™•ì„± ë©”íŠ¸ë¦­ì—ì„œ ë¡œì§ ì˜¤ë¥˜ê°€ ì§‘ì¤‘ì ìœ¼ë¡œ ë°œìƒí•˜ê³  ìˆìŒ
    """
    
    mock_pro_client.query.return_value = mock_analysis_response
    
    # ì¢…í•© ìš”ì•½ ìƒì„±
    summary = engine._generate_ai_failure_summary(model_failure_analysis)
    
    # ê²°ê³¼ ê²€ì¦
    assert summary is not None
    assert '2ê°œ ëª¨ë¸, ì´ 8ê±´ì˜ ì‹¤íŒ¨ ì‚¬ë¡€' in summary
    assert 'ì£¼ìš” ì‹¤íŒ¨ ì‚¬ìœ :' in summary
    assert 'ë©”íŠ¸ë¦­ë³„ í•µì‹¬ ì´ìŠˆ:' in summary
    assert 'ì¦‰ì‹œ ê°œì„  ê¶Œê³ ì‚¬í•­:' in summary


def test_failure_patterns_extraction(mock_engine):
    """ì‹¤íŒ¨ íŒ¨í„´ ì¶”ì¶œ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    engine, _, _ = mock_engine
    
    # AI ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
    ai_analyses = [
        {
            'model_name': 'model1',
            'analysis': {
                'analysis_content': 'ë¡œì§ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'analyzed_metrics': ['correctness']
            }
        },
        {
            'model_name': 'model2', 
            'analysis': {
                'analysis_content': 'ì£¼ì„ì´ ë¶€ì¡±í•˜ì—¬ ê°€ë…ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤. ë¬¸ì„œí™” ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'analyzed_metrics': ['clarity']
            }
        }
    ]
    
    # íŒ¨í„´ ì¶”ì¶œ ì‹¤í–‰
    patterns = engine._extract_failure_patterns(ai_analyses)
    
    # ê²°ê³¼ ê²€ì¦
    assert len(patterns) >= 2
    assert any('ë¡œì§ ì˜¤ë¥˜' in pattern[0] for pattern in patterns)
    assert any('ë¬¸ì„œí™” ë¶€ì¡±' in pattern[0] for pattern in patterns)
    assert all(isinstance(pattern[1], int) for pattern in patterns)  # ë¹„ìœ¨ì´ ì •ìˆ˜ì¸ì§€ í™•ì¸


def test_metric_issues_extraction(mock_engine):
    """ë©”íŠ¸ë¦­ë³„ ì´ìŠˆ ì¶”ì¶œ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    engine, _, _ = mock_engine
    
    # AI ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
    ai_analyses = [
        {
            'analysis': {
                'analysis_content': 'ì •í™•í•œ ë¡œì§ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'analyzed_metrics': ['correctness']
            }
        },
        {
            'analysis': {
                'analysis_content': 'ëª…í™•í•œ ì£¼ì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.',
                'analyzed_metrics': ['clarity']
            }
        }
    ]
    
    # ë©”íŠ¸ë¦­ ì´ìŠˆ ì¶”ì¶œ ì‹¤í–‰
    metric_issues = engine._extract_metric_issues(ai_analyses)
    
    # ê²°ê³¼ ê²€ì¦
    assert isinstance(metric_issues, dict)
    assert 'ì •í™•ì„±' in metric_issues or 'ëª…í™•ì„±' in metric_issues
    for metric, issue in metric_issues.items():
        assert len(issue) > 0
        assert 'í•„ìš”' in issue or 'ìš”êµ¬' in issue


def test_improvement_suggestions_extraction(mock_engine):
    """ê°œì„  ê¶Œê³ ì‚¬í•­ ì¶”ì¶œ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    engine, _, _ = mock_engine
    
    # AI ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
    ai_analyses = [
        {
            'analysis': {
                'analysis_content': 'ë‹¨ê¸°ì ìœ¼ë¡œ ì¦‰ì‹œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ìë™í™” ë„êµ¬ í™œìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
                'analyzed_metrics': ['correctness']
            }
        }
    ]
    
    # ê°œì„  ê¶Œê³ ì‚¬í•­ ì¶”ì¶œ ì‹¤í–‰
    suggestions = engine._extract_improvement_suggestions(ai_analyses)
    
    # ê²°ê³¼ ê²€ì¦
    assert isinstance(suggestions, list)
    assert len(suggestions) > 0
    assert any('ë‹¨ê¸°' in suggestion or 'ì¦‰ì‹œ' in suggestion for suggestion in suggestions)


def test_markdown_report_includes_ai_summary(mock_engine):
    """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œì— AI ì¢…í•© ìš”ì•½ì´ í¬í•¨ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
    engine, _, mock_pro_client = mock_engine
    
    # AI ë¶„ì„ ì‘ë‹µ ëª¨í‚¹
    mock_analysis_response = "ì¢…í•© ë¶„ì„ ê²°ê³¼ ë‚´ìš©"
    mock_pro_client.query.return_value = mock_analysis_response
    
    # í…ŒìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ ë°ì´í„°
    analysis_results = {
        'model_failure_analysis': {
            'model1': {
                'total_tests': 5,
                'total_failures': 2,
                'failure_rate': 0.4,
                'failed_metrics': {
                    'correctness': {
                        'failure_count': 2,
                        'avg_confidence': 0.75,
                        'translated_reasons': ['ì˜¤ë¥˜1', 'ì˜¤ë¥˜2']
                    }
                }
            }
        }
    }
    
    # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
    report = engine._generate_markdown_report(analysis_results)
    
    # AI ì¢…í•© ë¶„ì„ ì„¹ì…˜ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
    assert 'AI ê¸°ë°˜ ì¢…í•© ì‹¤íŒ¨ ë¶„ì„' in report
    assert 'ë¶„ì„ ëŒ€ìƒ' in report
    assert 'ë©”íŠ¸ë¦­ë³„ í•µì‹¬ ì´ìŠˆ' in report or 'ì¦‰ì‹œ ê°œì„  ê¶Œê³ ì‚¬í•­' in report


if __name__ == "__main__":
    pytest.main([__file__, "-v"])